# Mi primer blog, Bagging vs Boosting.


Hola,

Este es el primer blog que escribo. He decidido empezar a escribir una series de blogs relacionado con Machine Learning y Ciencia de Datos en español. Existe mucho material escrito en inglés, por lo que creo que no haré mucho aporte en ese espacio.

Recientemente comencé a buscar trabajo de manera formal y noté que tenía ciertas dificultades a la hora de responder las preguntas típicas en entrevistas para cargos relacionados a Machine Learning Engineer. Por esta razón, he decidido hacer un pequeño aporte educativo dirigido a personas en la misma situación en la que yo estuve, así como a aquellos que están comenzando en el fascinante mundo de la Inteligencia Artificial. 

Un obstáculo común es la barrera idiomática, especialmente considerando que la mayoría de los mejores materiales y blogs están en inglés. Por ello, de todos los animo a perder el miedo a aprender un nuevo idioma, como el inglés.
Suficiente ya de introducción, este primer artículo es sobre la diferencias entre Bagging y Boosting, dos métodos de Ensamble de Modelos, que buscan mejorar el rendimiento de modelos predictivos en tareas de clasificación o regresión. La noción básica es combinar el aprendizaje adquirido de varios modelos en lugar de uno sólo, para mejorar el rendimiento en tareas predictivas.

Los dos métodos principales son Bagging y Boosting. El objetivos de estos métodos es reducir la varianza un sólo estimador combinado varios estimadores de diferentes modelos, generando resultados con mayor estabilidad.
Ahora revisemos en profundidad como funcionan estas técnicas de ensamble:

## Bagging

Boostrap Aggregation, también conocido como bagging, es una técnica de ensamble de Machine Learning, cuyo objetivo es mejorar la estabilidad y el rendimiento de los modelos de predictivos, principalmente en tareas de clasificación y regresión. Reduce la varianza y ayuda a evitar el sobre-entrenamiento en modelos de Machine Learning, un fenómeno que hace los modelos se aprendan de "memoria" los datos usando durante el aprendizaje, y a la hora de revisar información nunca antes vista el modelo tenga un pésimo rendimiento.

## Boosting

## Referencias